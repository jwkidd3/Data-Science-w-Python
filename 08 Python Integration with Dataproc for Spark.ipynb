{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Python integration with Dataproc and spark.\n",
    "\n",
    "## History of Hadoop and Spark\n",
    "\n",
    "Map-Reduce is a programming paradigm that allowed computing at a new scale.\n",
    "\n",
    "Hadoop is an open source project that allowed map-reduce to be implemented widely.  But it is limited in many ways. \n",
    "\n",
    "Spark evolved the ideas of map-reduce and increased speed especially for iterative workflows and those that could fit in the main memory of the whole cluster. \n",
    "\n",
    "Pyspark is a python api for Spark. \n",
    "\n",
    "Dataproc is a cluster management system on GCP.  It allows easier running of hadoop and spark jobs without all the IT cluster overhead.  \n",
    "\n",
    "We will use the google cloud shell to avoid many of the security configuration headaches."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Implementation:\n",
    "\n",
    "I have added your email accounts to a GCP project called *gbq-learn01*.  You can create a 1 node cluster in region *us-west1*. Follow the directions in this quickstart but do not resize the cluster or shut it down.  Just do the steps to create the cluster and submit a job.  \n",
    "\n",
    "If you already have Dataproc access, you can use that instead. It may reduce the complexity for you. \n",
    "\n",
    "In the following quickstarts, I recommend you use the Google Cloud Shell to minimize environment variable settings and security issues.  In the upper center-right of the top box, you will see an icon that looks like a command line (next to the search magnifying glass icon).\n",
    "\n",
    "You can click on it and agree to open the cloud shell. This is a linux shell that we will use for the quicklab and lesson.  "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "First we will follow the following tutorial: \n",
    "[Quickstart using the gcloud command-line tool ](https://cloud.google.com/dataproc/docs/quickstarts/quickstart-gcloud)\n",
    "\n",
    "### *In creating the cluster, important note*\n",
    "\n",
    "Please use the flag: *--single-node*\n",
    "\n",
    "Like this:\n",
    "gcloud dataproc clusters create YOUR-CLUSTER-NAME --region=us-west1 --single-node\n",
    "\n",
    "This helps avoid quota limits with a large class.\n",
    "\n",
    "Once you have created a cluster, you will submit a spark job in a jar file.  The is written in Java or Scala.  Before continuing with the quickstart, let's try the same in Python.  "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "This is the shell command to execute the pyspark job.  \n",
    "\n",
    "gcloud dataproc jobs submit pyspark --cluster=YOUR-CLUSTER --region=us-west1 file:///usr/lib/spark/examples/src/main/python/pi.py -- 100\n",
    "\n",
    "Next examine [pi.py](https://github.com/apache/spark/blob/master/examples/src/main/python/pi.py) to examine the pyspark code you just ran. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "To learn more about how to send a local python file to your cluster look at [gcloud dataproc jobs submit pyspark](https://cloud.google.com/sdk/gcloud/reference/dataproc/jobs/submit/pyspark)\n",
    "\n",
    "You can also learn more about [PySpark](http://spark.apache.org/docs/latest/api/python/getting_started/index.html)\n",
    "\n",
    "If you want to learn about the [Dataproc client libraries](https://cloud.google.com/dataproc/docs/reference/libraries?cloudshell=true#linux-or-macos) you can learn to set up and control Dataproc from Python programs.  "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### When you are done, do not forget to shut down your cluster.  "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('data-train': conda)"
  },
  "interpreter": {
   "hash": "f3026f0e9e0031368890ff56328a08d504dfeef78f02a23762206680b534585a"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}